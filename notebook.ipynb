{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from os import getcwd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import shutil\n",
    "from shutil import rmtree\n",
    "import keras_preprocessing\n",
    "from keras_preprocessing import image\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "import fnmatch\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "import re\n",
    "from collections import Counter\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# detect and init the TPU\n",
    "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "tf.config.experimental_connect_to_cluster(tpu)\n",
    "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "\n",
    "# instantiate a distribution strategy\n",
    "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "\n",
    "GCS_PATH = KaggleDatasets().get_gcs_path('siim-isic-melanoma-classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lrfn(lr_start=0.00001, lr_max=0.000075, lr_min=0.000001, lr_rampup_epochs=20, lr_sustain_epochs=0, lr_exp_decay=.8):\n",
    "    lr_max = lr_max * tpu_strategy.num_replicas_in_sync\n",
    "    def lrfn(epoch):\n",
    "        if epoch < lr_rampup_epochs:\n",
    "            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n",
    "        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n",
    "            lr = lr_max\n",
    "        else:\n",
    "            lr = (lr_max - lr_min) * lr_exp_decay ** (epoch - lr_rampup_epochs - lr_sustain_epochs) + lr_min\n",
    "        return lr\n",
    "    return lrfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data leakage between training and testing data over PatientId column\n",
    "def check_for_leakage(df1, df2, patient_col):\n",
    "    \"\"\"\n",
    "    Return True if there any patients are in both df1 and df2.\n",
    "\n",
    "    Args:\n",
    "        df1 (dataframe): dataframe describing first dataset\n",
    "        df2 (dataframe): dataframe describing second dataset\n",
    "        patient_col (str): string name of column with patient IDs\n",
    "    \n",
    "    Returns:\n",
    "        leakage (bool): True if there is leakage, otherwise False\n",
    "    \"\"\"\n",
    "\n",
    "    df1_patients_unique = df1[patient_col].values\n",
    "    df2_patients_unique = df2[patient_col].values\n",
    "    \n",
    "    patients_in_both_groups = len(list(set(df1_patients_unique).intersection(set(df2_patients_unique))))\n",
    "\n",
    "    # leakage contains true if there is patient overlap, otherwise false.\n",
    "    leakage = False if patients_in_both_groups == 0 else True # boolean (true if there is at least 1 patient in both groups)\n",
    "    return leakage\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(\"/kaggle/input/siim-isic-melanoma-classification/train.csv\")\n",
    "test_df = pd.read_csv(\"/kaggle/input/siim-isic-melanoma-classification/test.csv\")\n",
    "print(f\"Data Leakage: {check_for_leakage(train_df, test_df, 'patient_id')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16 * tpu_strategy.num_replicas_in_sync\n",
    "Epochs = 16\n",
    "IMG_HEIGHT = 1024\n",
    "IMG_WIDTH = 1024\n",
    "TRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/tfrecords/train*.tfrec')\n",
    "TEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/tfrecords/test*.tfrec')\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "checkpoint_filepath = '/kaggle/input/siim-isic-melanoma-classification/'\n",
    "\n",
    "\n",
    "# instantiating the model in the strategy scope creates the model on the TPU\n",
    "with tpu_strategy.scope():\n",
    "    print('Loading InceptionResNet version 2 model...')\n",
    "    pre_trained_model = InceptionResNetV2(include_top = False,\n",
    "                        weights = 'imagenet',\n",
    "                        input_tensor = None,\n",
    "                        input_shape = (IMG_HEIGHT,IMG_WIDTH,3))\n",
    "\n",
    "    print('Disabling training of all layers in the pre-trained model')\n",
    "    # Make all the layers in the pre-trained model non-trainable\n",
    "    for layer in pre_trained_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    print('Appending pre-trained model with extra layers...')\n",
    "    model = tf.keras.Sequential([\n",
    "            pre_trained_model,\n",
    "            tf.keras.layers.GlobalAveragePooling2D(),\n",
    "            tf.keras.layers.Dense(512, activation = 'relu'),\n",
    "            tf.keras.layers.Dropout(0.1),\n",
    "            tf.keras.layers.Dense(256, activation = 'relu'),\n",
    "            tf.keras.layers.Dropout(0.1),\n",
    "            tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "            tf.keras.layers.Dropout(0.1),\n",
    "            tf.keras.layers.Dense(16, activation = 'relu'),\n",
    "            tf.keras.layers.Dropout(0.1),\n",
    "            tf.keras.layers.Dense(1, activation = 'sigmoid')])\n",
    "\n",
    "\n",
    "    # The model weights (that are considered the best) are loaded into the model.\n",
    "    # model.load_weights(checkpoint_filepath)\n",
    "\n",
    "    print('Defining optimizer, loss and metrics...')\n",
    "    model.compile(optimizer = 'adam', \n",
    "                  loss = 'binary_crossentropy', \n",
    "                  metrics = tf.keras.metrics.AUC(name='auc'))\n",
    "\n",
    "print('\\nModel Summary:')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n",
    "    image = tf.reshape(image, [IMG_HEIGHT, IMG_WIDTH, 3]) # explicit size needed for TPU\n",
    "    return image\n",
    "\n",
    "def read_labeled_tfrecord(example):\n",
    "    LABELED_TFREC_FORMAT = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
    "        \"target\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
    "    image = decode_image(example['image'])\n",
    "    label = tf.cast(example['target'], tf.int32)\n",
    "    return image, label # returns a dataset of (image, label) pairs\n",
    "\n",
    "\n",
    "def read_unlabeled_tfrecord(example):\n",
    "    UNLABELED_TFREC_FORMAT = {\n",
    "            \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
    "            \"image_name\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\n",
    "            # class is missing, this competitions's challenge is to predict flower classes for the test dataset\n",
    "        }\n",
    "    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n",
    "    image = decode_image(example['image'])\n",
    "    idnum = example['image_name']\n",
    "    return image, idnum # returns a dataset of image(s)\n",
    "\n",
    "def data_augment(image, label):\n",
    "    # data augmentation. Thanks to the dataset.prefetch(AUTO) statement in the next function (below),\n",
    "    # this happens essentially for free on TPU. Data pipeline code is executed on the \"CPU\" part\n",
    "    # of the TPU while the TPU itself is computing gradients.\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    #image = tf.image.random_saturation(image, 0, 2)\n",
    "    return image, label\n",
    "\n",
    "def get_test_dataset(ordered = False):\n",
    "    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    return dataset\n",
    "\n",
    "def count_data_items(filenames):\n",
    "    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)\n",
    "\n",
    "def load_dataset(filenames, labeled = True, ordered = False):\n",
    "    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n",
    "    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n",
    "\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False # disable order, increase speed\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n",
    "    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n",
    "    return dataset\n",
    "\n",
    "print('Performing Data Augmentation...')\n",
    "# Over sampling of data\n",
    "#Step 1 - Get labels and their countings\n",
    "raw_training_dataset = load_dataset(TRAINING_FILENAMES, labeled=True, ordered=False)\n",
    "label_counter = Counter()\n",
    "for images, labels in raw_training_dataset:\n",
    "    label_counter.update([labels.numpy()])\n",
    "del raw_training_dataset    \n",
    "label_counting_sorted = label_counter.most_common()\n",
    "NUM_TRAINING_IMAGES = sum([x[1] for x in label_counting_sorted])\n",
    "print(\"\\nNumber of examples in the original training dataset: {}\".format(NUM_TRAINING_IMAGES))\n",
    "print(\"Labels in the original training dataset, sorted by occurrence\")\n",
    "print(label_counting_sorted)\n",
    "\n",
    "#Step 2 - Define the number of repetitions for each class\n",
    "# We want each class occur at least (approximately) `TARGET_MIN_COUNTING` times\n",
    "TARGET_MIN_COUNTING = math.ceil(0.2 * NUM_TRAINING_IMAGES)\n",
    "\n",
    "def get_num_of_repetition_for_class(class_id):\n",
    "    counting = label_counter[class_id]\n",
    "    if counting >= TARGET_MIN_COUNTING:\n",
    "        return 1.0\n",
    "    elif counting == 0:\n",
    "        return 0\n",
    "    num_to_repeat = TARGET_MIN_COUNTING / counting\n",
    "    return num_to_repeat\n",
    "\n",
    "numbers_of_repetition_for_classes = {class_id: get_num_of_repetition_for_class(class_id) for class_id in range(104)}\n",
    "{k: v for k, v in sorted(numbers_of_repetition_for_classes.items(), key=lambda item: item[1], reverse=True) if v > 1}\n",
    "\n",
    "#Step 3 - Define the number of repetitions for each training example\n",
    "keys_tensor = tf.constant([k for k in numbers_of_repetition_for_classes])\n",
    "vals_tensor = tf.constant([numbers_of_repetition_for_classes[k] for k in numbers_of_repetition_for_classes])\n",
    "table = tf.lookup.StaticHashTable(tf.lookup.KeyValueTensorInitializer(keys_tensor, vals_tensor), -1)\n",
    "\n",
    "def get_num_of_repetition_for_example(training_example):\n",
    "    _, label = training_example\n",
    "    num_to_repeat = table.lookup(label)\n",
    "    num_to_repeat_integral = tf.cast(int(num_to_repeat), tf.float32)\n",
    "    residue = num_to_repeat - num_to_repeat_integral\n",
    "    num_to_repeat = num_to_repeat_integral + tf.cast(tf.random.uniform(shape=()) <= residue, tf.float32)\n",
    "    return tf.cast(num_to_repeat, tf.int64)\n",
    "\n",
    "#Step 4 - Use data augmentation to avoid (exactly) same images appear too many times\n",
    "\n",
    "def get_mat(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n",
    "    # returns 3x3 transformmatrix which transforms indicies\n",
    "        \n",
    "    # CONVERT DEGREES TO RADIANS\n",
    "    rotation = math.pi * rotation / 180.\n",
    "    shear = math.pi * shear / 180.\n",
    "    \n",
    "    # ROTATION MATRIX\n",
    "    c1 = tf.math.cos(rotation)\n",
    "    s1 = tf.math.sin(rotation)\n",
    "    one = tf.constant([1],dtype='float32')\n",
    "    zero = tf.constant([0],dtype='float32')\n",
    "    rotation_matrix = tf.reshape( tf.concat([c1,s1,zero, -s1,c1,zero, zero,zero,one],axis=0),[3,3] )\n",
    "        \n",
    "    # SHEAR MATRIX\n",
    "    c2 = tf.math.cos(shear)\n",
    "    s2 = tf.math.sin(shear)\n",
    "    shear_matrix = tf.reshape( tf.concat([one,s2,zero, zero,c2,zero, zero,zero,one],axis=0),[3,3] )    \n",
    "    \n",
    "    # ZOOM MATRIX\n",
    "    zoom_matrix = tf.reshape( tf.concat([one/height_zoom,zero,zero, zero,one/width_zoom,zero, zero,zero,one],axis=0),[3,3] )\n",
    "    \n",
    "    # SHIFT MATRIX\n",
    "    shift_matrix = tf.reshape( tf.concat([one,zero,height_shift, zero,one,width_shift, zero,zero,one],axis=0),[3,3] )\n",
    "    \n",
    "    return K.dot(K.dot(rotation_matrix, shear_matrix), K.dot(zoom_matrix, shift_matrix))\n",
    "\n",
    "\n",
    "def transform(image, label):\n",
    "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
    "    # output - image randomly rotated, sheared, zoomed, and shifted\n",
    "    DIM = IMG_HEIGHT #IMAGE_SIZE[0]\n",
    "    XDIM = DIM%2 #fix for size 331\n",
    "    \n",
    "    rot = 15. * tf.random.normal([1],dtype='float32')\n",
    "    shr = 5. * tf.random.normal([1],dtype='float32') \n",
    "    h_zoom = 1.0 + tf.random.normal([1],dtype='float32')/10.\n",
    "    w_zoom = 1.0 + tf.random.normal([1],dtype='float32')/10.\n",
    "    h_shift = 16. * tf.random.normal([1],dtype='float32') \n",
    "    w_shift = 16. * tf.random.normal([1],dtype='float32') \n",
    "  \n",
    "    # GET TRANSFORMATION MATRIX\n",
    "    m = get_mat(rot,shr,h_zoom,w_zoom,h_shift,w_shift) \n",
    "\n",
    "    # LIST DESTINATION PIXEL INDICES\n",
    "    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n",
    "    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n",
    "    z = tf.ones([DIM*DIM],dtype='int32')\n",
    "    idx = tf.stack( [x,y,z] )\n",
    "    \n",
    "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
    "    idx2 = K.dot(m,tf.cast(idx,dtype='float32'))\n",
    "    idx2 = K.cast(idx2,dtype='int32')\n",
    "    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n",
    "    \n",
    "    # FIND ORIGIN PIXEL VALUES           \n",
    "    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n",
    "    d = tf.gather_nd(image,tf.transpose(idx3))\n",
    "        \n",
    "    return tf.reshape(d,[DIM,DIM,3]), label\n",
    "\n",
    "\n",
    "#Step 5 - A method to get oversampled training dataset\n",
    "def get_training_dataset_with_oversample(repeat_dataset=True, oversample=False, augumentation=False):\n",
    "    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n",
    "    \n",
    "    if oversample:\n",
    "        dataset = dataset.flat_map(lambda image, label: tf.data.Dataset.from_tensors((image, label)).repeat(get_num_of_repetition_for_example((image, label))))\n",
    "    if augumentation:\n",
    "        dataset = dataset.map(transform, num_parallel_calls=AUTO)\n",
    "    if repeat_dataset:\n",
    "        dataset = dataset.repeat() # the training dataset must repeat for several epochs\n",
    "    \n",
    "    dataset = dataset.shuffle(20000)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    return dataset\n",
    "\n",
    "#Step 6 - Check oversampled dataset\n",
    "oversampled_training_dataset = get_training_dataset_with_oversample(repeat_dataset=False, oversample=True, augumentation=True)\n",
    "\n",
    "label_counter_2 = Counter()\n",
    "for images, labels in oversampled_training_dataset:\n",
    "    label_counter_2.update(labels.numpy())\n",
    "\n",
    "del oversampled_training_dataset\n",
    "\n",
    "label_counting_sorted_2 = label_counter_2.most_common()\n",
    "\n",
    "NUM_TRAINING_IMAGES_OVERSAMPLED = sum([x[1] for x in label_counting_sorted_2])\n",
    "print(\"\\nNumber of examples in the oversampled training dataset: {}\".format(NUM_TRAINING_IMAGES_OVERSAMPLED))\n",
    "\n",
    "print(\"Labels in the oversampled training dataset, sorted by occurrence\")\n",
    "print(label_counting_sorted_2)\n",
    "\n",
    "print('\\nData Augmentation completed...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StepsPerEpoch = count_data_items(TRAINING_FILENAMES)//BATCH_SIZE\n",
    "\n",
    "weight_for_0 = (1 / 32542)*(39161)/2.0 \n",
    "weight_for_1 = (1 / 6619)*(39161)/2.0\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = checkpoint_filepath,\n",
    "    save_weights_only = True,\n",
    "    monitor = 'val_acc',\n",
    "    mode = 'max',\n",
    "    save_best_only = True)\n",
    "\n",
    "lrfn = build_lrfn()\n",
    "\n",
    "print('Training the model...')\n",
    "\n",
    "history = model.fit(get_training_dataset_with_oversample(repeat_dataset=True, oversample=True, augumentation=True),\n",
    "                    epochs = Epochs, \n",
    "                    steps_per_epoch = StepsPerEpoch,\n",
    "                    callbacks = [tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1), model_checkpoint_callback],\n",
    "                    class_weight = class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "# Saving the model\n",
    "filename = 'saved_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "# Loading the saved model\n",
    "model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('./model.h5')\n",
    "# reload_model = tf.keras.models.load_model('./model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting AUC curve\n",
    "metrics =  ['loss', 'auc']\n",
    "for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplot(2,1,n+1)\n",
    "    plt.plot(history.epoch,  history.history[metric], label='Train')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    if metric == 'loss':\n",
    "      plt.ylim([0, plt.ylim()[1]])\n",
    "    elif metric == 'auc':\n",
    "      plt.ylim([0.8,1])\n",
    "    else:\n",
    "      plt.ylim([0,1])\n",
    "\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting test results\n",
    "NUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\n",
    "\n",
    "test_ds = get_test_dataset(ordered=True)\n",
    "\n",
    "print('Computing predictions...')\n",
    "test_images_ds = test_ds.map(lambda image, idnum: image)\n",
    "output = model.predict(test_images_ds)\n",
    "\n",
    "print('Generating submission.csv file...')\n",
    "test_ids_ds = test_ds.map(lambda image, idnum: idnum).unbatch()\n",
    "test_ids = next(iter(test_ids_ds.batch(NUM_TEST_IMAGES))).numpy().astype('U') # all in one batch\n",
    "\n",
    "output_df = pd.DataFrame({'image_name': test_ids, 'target': np.concatenate(output)})\n",
    "\n",
    "output_file = pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/sample_submission.csv')\n",
    "del output_file['target']\n",
    "output_file = output_file.merge(output_df, on='image_name')\n",
    "output_file.to_csv('./submission_image.csv', index=False)\n",
    "print('submission.csv file generated...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing numerical data\n",
    "training_data = pd.read_csv(\"/kaggle/input/siim-isic-melanoma-classification/train.csv\")\n",
    "X = training_data[['sex', 'age_approx', 'anatom_site_general_challenge']]\n",
    "y = training_data[['target']]\n",
    "\n",
    "#One hot encoding of categorical data\n",
    "X = pd.get_dummies(X, columns = ['sex'])\n",
    "X = pd.get_dummies(X, columns = ['anatom_site_general_challenge'])\n",
    "\n",
    "# Create a minimum and maximum processor object\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# Create an object to transform the data to fit minmax processor\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "# Run the normalizer on the dataframe\n",
    "X = pd.DataFrame(X)\n",
    "\n",
    "#Imputing null values with 0\n",
    "X[0] = X[0].fillna(0)\n",
    "\n",
    "#Performing oversampling using SMOTE (Synthetic Minority Oversampling Technique)\n",
    "sm = SMOTE(random_state=42)\n",
    "X_numerical, y_numerical = sm.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating the model in the strategy scope creates the model on the TPU\n",
    "with tpu_strategy.scope():\n",
    "    numerical_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(512, activation='relu', input_shape = [9]),\n",
    "            tf.keras.layers.Dropout(0.1),    \n",
    "            tf.keras.layers.Dense(256, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.1),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.1),\n",
    "            tf.keras.layers.Dense(32, activation='relu'),    \n",
    "            tf.keras.layers.Dropout(0.1),\n",
    "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "    numerical_model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "                    loss = 'binary_crossentropy',\n",
    "                    metrics = [tf.keras.metrics.AUC()])\n",
    "\n",
    "numerical_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 400\n",
    "STEPS_PER_EPOCH = math.ceil(len(X)/EPOCHS)\n",
    "\n",
    "weight_for_0 = (1 / len(y_numerical[y_numerical == 0]))*len(X_numerical)/2.0 \n",
    "weight_for_1 = (1 / len(y_numerical[y_numerical == 1]))*len(X_numerical)/2.0\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "history = numerical_model.fit(\n",
    "    X, y, \n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    class_weight = class_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting test results\n",
    "test_data = pd.read_csv(\"/kaggle/input/siim-isic-melanoma-classification/test.csv\")\n",
    "X_test = test_data[['sex', 'age_approx', 'anatom_site_general_challenge']]\n",
    "\n",
    "#One hot encoding of categorical data\n",
    "X_test = pd.get_dummies(X_test, columns = ['sex'])\n",
    "X_test = pd.get_dummies(X_test, columns = ['anatom_site_general_challenge'])\n",
    "\n",
    "# Create a minimum and maximum processor object\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# Create an object to transform the data to fit minmax processor\n",
    "X_test = min_max_scaler.fit_transform(X_test)\n",
    "# Run the normalizer on the dataframe\n",
    "X_test = pd.DataFrame(X_test)\n",
    "\n",
    "#Imputing null values with 0\n",
    "X_test[0] = X_test[0].fillna(0)\n",
    "\n",
    "\n",
    "# below section coped from other notebook\n",
    "\n",
    "test_ds = get_test_dataset(ordered=True)\n",
    "\n",
    "print('Computing predictions...')\n",
    "test_images_ds = test_ds.map(lambda image, idnum: image)\n",
    "output = np.round(numerical_model.predict(X_test))\n",
    "\n",
    "print('Generating submission.csv file...')\n",
    "test_ids_ds = test_ds.map(lambda image, idnum: idnum).unbatch()\n",
    "test_ids = next(iter(test_ids_ds.batch(NUM_TEST_IMAGES))).numpy().astype('U') # all in one batch\n",
    "\n",
    "output_df = pd.DataFrame({'image_name': test_ids, 'target': np.concatenate(output)})\n",
    "\n",
    "output_file = pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/sample_submission.csv')\n",
    "del output_file['target']\n",
    "output_file = output_file.merge(output_df, on='image_name')\n",
    "output_file.to_csv('submission_numerical.csv', index=False)\n",
    "print('submission.csv file generated...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
